{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep Image Matching loaded in 3.230 seconds.\n",
            "\u001b[1;33m2024-05-13 18:43:32 | [WARNING ] assets/example_cyprus/results_sift+lightglue_matching_lowres_quality_high already exists, but the '--force' option is used. Deleting the folder.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import deep_image_matching as dim\n",
        "\n",
        "params = {\n",
        "    \"dir\": \"./assets/example_cyprus\",\n",
        "    \"pipeline\": \"sift+lightglue\",\n",
        "    \"strategy\": \"matching_lowres\",\n",
        "    \"quality\": \"high\",\n",
        "    \"tiling\": \"preselection\",\n",
        "    \"camera_options\": \"./assets/example_cyprus/cameras.yaml\",\n",
        "    \"openmvg\": None,\n",
        "}\n",
        "config = dim.Config(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run feature extraction and matching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded SuperPoint model\n",
            "Loaded LightGlue model\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ] Running image matching with the following configuration:\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Image folder: assets/example_cyprus/images\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Output folder: assets/example_cyprus/results_sift+lightglue_matching_lowres_quality_high\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Number of images: 10\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Matching strategy: matching_lowres\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Image quality: HIGH\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Tile selection: PRESELECTION\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Feature extraction method: sift\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Matching method: lightglue\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   Geometric verification: PYDEGENSAC\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ]   CUDA available: True\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ] Low resolution matching, generating pairs ..\u001b[0m\n",
            "Loaded SuperPoint model\n",
            "\u001b[0;37m2024-05-13 18:43:34 | [INFO    ] Extracting features from downsampled images...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]/home/francesco/miniforge3/envs/dim/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "100%|██████████| 10/10 [00:02<00:00,  4.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;37m2024-05-13 18:43:36 | [INFO    ] Matching downsampled images...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 45/45 [00:00<00:00, 49.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;37m2024-05-13 18:43:37 | [INFO    ] Found 28 pairs.\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:37 | [INFO    ] Extracting features with sift...\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:37 | [INFO    ] sift configuration: \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'contrastThreshold': 0.04,\n",
            " 'detection_threshold': 0.2,\n",
            " 'edgeThreshold': 10,\n",
            " 'max_num_keypoints': 4000,\n",
            " 'model_name': 'aliked-n16rot',\n",
            " 'nOctaveLayers': 3,\n",
            " 'n_features': 4000,\n",
            " 'name': 'sift',\n",
            " 'nms_radius': 3,\n",
            " 'sigma': 1.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:38 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:00<00:07,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:39 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [00:01<00:06,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:39 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [00:02<00:05,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:40 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [00:03<00:04,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:41 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [00:04<00:04,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:42 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [00:04<00:03,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:43 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [00:05<00:02,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:43 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [00:06<00:01,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:44 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [00:07<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:45 | [WARNING ] No scores found in features\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;37m2024-05-13 18:43:45 | [INFO    ] Features extracted!\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:45 | [INFO    ] Matching features with lightglue...\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:45 | [INFO    ] lightglue configuration: \u001b[0m\n",
            "{'add_laf': False,\n",
            " 'add_scale_ori': False,\n",
            " 'depth_confidence': 0.95,\n",
            " 'descriptor_dim': 256,\n",
            " 'filter_threshold': 0.1,\n",
            " 'flash': True,\n",
            " 'input_dim': 256,\n",
            " 'mp': False,\n",
            " 'n_layers': 9,\n",
            " 'name': 'lightglue',\n",
            " 'num_heads': 4,\n",
            " 'scale_coef': 1.0,\n",
            " 'weights': None,\n",
            " 'width_confidence': 0.99}\n",
            "\u001b[0;37m2024-05-13 18:43:45 | [INFO    ] Matching features...\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:45 | [INFO    ] \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/28 [00:00<?, ?it/s]/home/francesco/miniforge3/envs/dim/lib/python3.10/site-packages/kornia/feature/integrated.py:464: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  hw1_ = torch.tensor(hw1, device=dev)\n",
            "/home/francesco/miniforge3/envs/dim/lib/python3.10/site-packages/kornia/feature/integrated.py:468: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  hw2_ = torch.tensor(hw2, device=dev)\n",
            "100%|██████████| 28/28 [00:05<00:00,  4.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;37m2024-05-13 18:43:51 | [INFO    ] [Timer] | [matching] generate_pairs=4.809, extract_features=8.049, Match pair=0.201, Total execution=18.494\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:51 | [INFO    ] [Timer] | [Deep Image Matching] Total execution=0.000\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "matcher = dim.ImageMatcher(config)\n",
        "feature_path, match_path = matcher.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Export matches to COLMAP format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33m2024-05-13 18:43:51 | [WARNING ] Was not possible to load the first image to initialize cam0\u001b[0m\n",
            "\u001b[1;33m2024-05-13 18:43:51 | [WARNING ] Was not possible to load the first image to initialize cam1\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 1418.77it/s]\n",
            "28it [00:00, 11114.95it/s]            \n",
            "23it [00:00, 10867.30it/s]            \n"
          ]
        }
      ],
      "source": [
        "dim.io.export_to_colmap(\n",
        "    img_dir=config.general[\"image_dir\"],\n",
        "    feature_path=feature_path,\n",
        "    match_path=match_path,\n",
        "    database_path=config.general[\"output_dir\"] / \"database.db\",\n",
        "    camera_config_path=config.general[\"camera_options\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run reconstruction with pycolmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;37m2024-05-13 18:43:51 | [INFO    ] Running 3D reconstruction...\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:51 | [INFO    ] Reconstructed 1 model(s).\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:51 | [INFO    ] Largest model is #0 with 2 images.\u001b[0m\n",
            "\u001b[0;37m2024-05-13 18:43:51 | [INFO    ] Exporting model...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I20240513 18:43:51.269966 287020 misc.cc:198] \n",
            "==============================================================================\n",
            "Loading database\n",
            "==============================================================================\n",
            "I20240513 18:43:51.270964 287020 database_cache.cc:54] Loading cameras...\n",
            "I20240513 18:43:51.270999 287020 database_cache.cc:64]  1 in 0.000s\n",
            "I20240513 18:43:51.271013 287020 database_cache.cc:72] Loading matches...\n",
            "I20240513 18:43:51.271080 287020 database_cache.cc:78]  23 in 0.000s\n",
            "I20240513 18:43:51.271086 287020 database_cache.cc:94] Loading images...\n",
            "I20240513 18:43:51.272256 287020 database_cache.cc:143]  10 in 0.001s (connected 8)\n",
            "I20240513 18:43:51.272287 287020 database_cache.cc:154] Building correspondence graph...\n",
            "I20240513 18:43:51.272884 287020 database_cache.cc:190]  in 0.001s (ignored 0)\n",
            "I20240513 18:43:51.272900 287020 timer.cc:91] Elapsed time: 0.000 [minutes]\n",
            "I20240513 18:43:51.273319 287020 misc.cc:198] \n",
            "==============================================================================\n",
            "Finding good initial image pair\n",
            "==============================================================================\n",
            "I20240513 18:43:51.305038 287020 misc.cc:198] \n",
            "==============================================================================\n",
            "Initializing with image pair #2 and #1\n",
            "==============================================================================\n",
            "I20240513 18:43:51.305308 287020 misc.cc:198] \n",
            "==============================================================================\n",
            "Global bundle adjustment\n",
            "==============================================================================\n",
            "I20240513 18:43:51.323562 287020 misc.cc:205] \n",
            "Bundle adjustment report\n",
            "------------------------\n",
            "I20240513 18:43:51.323596 287020 bundle_adjustment.cc:942] \n",
            "    Residuals : 452\n",
            "   Parameters : 344\n",
            "   Iterations : 101\n",
            "         Time : 0.0180709 [s]\n",
            " Initial cost : 4.57103 [px]\n",
            "   Final cost : 1.45307 [px]\n",
            "  Termination : No convergence\n",
            "\n",
            "I20240513 18:43:51.323717 287020 incremental_mapper.cc:160] => Filtered observations: 128\n",
            "I20240513 18:43:51.323724 287020 incremental_mapper.cc:167] => Filtered images: 0\n",
            "I20240513 18:43:51.354473 287020 misc.cc:198] \n",
            "==============================================================================\n",
            "Finding good initial image pair\n",
            "==============================================================================\n",
            "I20240513 18:43:51.354636 287020 incremental_mapper.cc:404] => No good initial image pair found.\n",
            "I20240513 18:43:51.354652 287020 timer.cc:91] Elapsed time: 0.001 [minutes]\n"
          ]
        }
      ],
      "source": [
        "model = dim.reconstruction.pycolmap_reconstruction(\n",
        "    database_path=config.general[\"output_dir\"] / \"database.db\",\n",
        "    sfm_dir=config.general[\"output_dir\"],\n",
        "    image_dir=config.general[\"image_dir\"],\n",
        "    refine_intrinsics=False,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deep_image_matching",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
