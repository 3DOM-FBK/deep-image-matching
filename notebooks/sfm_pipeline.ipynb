{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "from pprint import pprint\n",
    "\n",
    "from deep_image_matching import logger, timer\n",
    "from deep_image_matching.config import Config\n",
    "from deep_image_matching.image_matching import ImageMatching\n",
    "from deep_image_matching.io.h5_to_db import export_to_colmap\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of possible configurations and chose one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available configurations:\")\n",
    "pprint(Config.get_pipelines())\n",
    "print(\"Available matching strategy:\")\n",
    "pprint(Config.get_matching_strategies())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to build a dictionary with the input processing parameters (they are the same as the input parameters for the CLI and GUI) and pass it to the Config class to initialize the configuration object.\n",
    "Refer to the README for more information about the parameters.\n",
    "\n",
    "Note that there are two possible approaches for defining the paths needed for the processing (i.e., input images and output results):\n",
    "- You can pass a single parameter defining the processing directory (with 'dir' key). Deep-Image-Matching will search for the images inside an 'image' subdirectory and will save the results in a 'results_{processing_params}' subdirectory, where {processing_params} are some information on the processing parameters used.\n",
    "- or you can manually specify the input images directory (with 'images' key) and the output results directory (with 'outs' key).\n",
    "\n",
    "Note, that these parameters are the same as the ones used in the CLI (the GUI is not updated yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_params = {\n",
    "    \"dir\": \"../assets/example_cyprus\",\n",
    "    \"pipeline\": \"superpoint+lightglue\",\n",
    "    \"strategy\": \"matching_lowres\",\n",
    "    \"quality\": \"high\",\n",
    "    \"tiling\": \"preselection\",\n",
    "    \"skip_reconstruction\": False,\n",
    "    \"force\": True,\n",
    "    \"camera_options\": \"../config/cameras.yaml\",\n",
    "    \"openmvg\": None,\n",
    "}\n",
    "config = Config(cli_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Config general:\")\n",
    "pprint(config.general)\n",
    "print(\"Config extractor:\")\n",
    "pprint(config.extractor)\n",
    "print(\"Config matcher:\")\n",
    "pprint(config.matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know what you are doing, you can update some config parameters directly updating the config dictionary (check the file config.py in the scr folder for the available parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - General configuration\n",
    "config.general[\"min_inliers_per_pair\"] = 10\n",
    "config.general[\"min_inlier_ratio_per_pair\"] = 0.2\n",
    "\n",
    "# - SuperPoint configuration\n",
    "config.extractor[\"max_keypoints\"] = 8000\n",
    "\n",
    "# - LightGue configuration\n",
    "config.matcher[\"filter_threshold\"] = 0.1\n",
    "\n",
    "# Save configuration to a json file in the output directory\n",
    "config.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = config.general[\"image_dir\"]\n",
    "output_dir = config.general[\"output_dir\"]\n",
    "matching_strategy = config.general[\"matching_strategy\"]\n",
    "extractor = config.extractor[\"name\"]\n",
    "matcher = config.matcher[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the ImageMatching class \n",
    "This will be used for performing the image matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_matching = ImageMatching(\n",
    "    imgs_dir=imgs_dir,\n",
    "    output_dir=output_dir,\n",
    "    matching_strategy=matching_strategy,\n",
    "    local_features=extractor,\n",
    "    matching_method=matcher,\n",
    "    pair_file=config.general[\"pair_file\"],\n",
    "    retrieval_option=config.general[\"retrieval\"],\n",
    "    overlap=config.general[\"overlap\"],\n",
    "    existing_colmap_model=config.general[\"db_path\"],\n",
    "    custom_config=config.as_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate pairs to be matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_path = img_matching.generate_pairs()\n",
    "timer.update(\"generate_pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to rotate images so they will be all \"upright\", useful for deep-learning approaches that usually are not rotation invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.general[\"upright\"]:\n",
    "    img_matching.rotate_upright_images()\n",
    "    timer.update(\"rotate_upright_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = img_matching.extract_features()\n",
    "timer.update(\"extract_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_path = img_matching.match_pairs(feature_path)\n",
    "timer.update(\"matching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If features have been extracted on \"upright\" images, this function bring features back to their original image orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.general[\"upright\"]:\n",
    "    img_matching.rotate_back_features(feature_path)\n",
    "    timer.update(\"rotate_back_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export in colmap format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIM assigns camera models to images based on the options defined in `config/cameras.yaml`. To load camera model options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.general[\"camera_options\"], \"r\") as file:\n",
    "    camera_options = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can assign camera models with a dictionary. \n",
    "\n",
    "For images not assigned to specific `cam<x>` camera groups, the options specified under `general` are applied. The `camera_model` can be selected from `[\"simple-pinhole\", \"pinhole\", \"simple-radial\", \"opencv\"]`. It's worth noting that it's easily possible to extend this to include all the classical COLMAP camera models. Cameras can either be shared among all images (`single_camera == True`), or each camera can have a different camera model (`single_camera == False`).\n",
    "\n",
    "A subset of images can share intrinsics using `cam<x>` key, by specifying the `camera_model` along with the names of the images separated by commas. There's no limit to the number of `cam<x>` entries you can use.\n",
    "\n",
    "**Note**: Use the SIMPLE-PINHOLE camera model if you want to export the solution to Metashape later, as there are some bugs in COLMAP (or pycolamp) when exportingthe solution in the Bundler format.\n",
    "e.g., using FULL-OPENCV camera model, the principal point is not exported correctly and the tie points are wrong in Metashape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_options = {\n",
    "   'general' : {\n",
    "    \"camera_model\" : \"pinhole\", # [\"simple-pinhole\", \"pinhole\", \"simple-radial\", \"opencv\"]\n",
    "    \"single_camera\" : True,\n",
    "   },\n",
    "   'cam0' : {\n",
    "        \"camera_model\" : \"pinhole\",\n",
    "        \"images\" : \"DSC_6468.JPG,DSC_6468.JPG\",\n",
    "   },\n",
    "   'cam1' : {\n",
    "        \"camera_model\" : \"pinhole\",\n",
    "        \"images\" : \"\",\n",
    "   },\n",
    "}\n",
    "    \n",
    "database_path = output_dir / \"database.db\"\n",
    "export_to_colmap(\n",
    "    img_dir=imgs_dir,\n",
    "    feature_path=feature_path,\n",
    "    match_path=match_path,\n",
    "    database_path=database_path,\n",
    "    camera_options=camera_options,\n",
    ")\n",
    "timer.update(\"export_to_colmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'camera_model': 'pinhole', 'single_camera': True}, 'cam0': {'camera_model': 'pinhole', 'images': 'DSC_6468.jpg,DSC_6468.jpg'}, 'cam1': {'camera_model': 'pinhole', 'images': ''}}\n"
     ]
    }
   ],
   "source": [
    "print(camera_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run reconstruction\n",
    "If --skip_reconstruction is not specified (from CLI or in the cli_params dictonary), run reconstruction with pycolmap\n",
    "\n",
    "Try first to import the pycolmap module, if it fails, skip reconstruction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.general[\"skip_reconstruction\"]:\n",
    "    use_pycolmap = True\n",
    "    try:\n",
    "        pycolmap = import_module(\"pycolmap\")\n",
    "    except ImportError:\n",
    "        logger.error(\"Pycomlap is not available.\")\n",
    "        use_pycolmap = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the pycolmap module is imported, define some parameters for the reconstruction and run it.\n",
    "(Optional) You can specify some reconstruction configuration in a dictionary, or leave the dictionary empty to use the default configuration.\n",
    "\n",
    "  ``` python  \n",
    "  reconst_opts = {\n",
    "          \"ba_refine_focal_length\": True,\n",
    "          \"ba_refine_principal_point\": False,\n",
    "          \"ba_refine_extra_params\": False,\n",
    "      }\n",
    "  ```\n",
    "  or\n",
    "  ``` python\n",
    "  reconst_opts = {}\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config.general[\"skip_reconstruction\"] and use_pycolmap:\n",
    "    # import reconstruction module\n",
    "    from deep_image_matching import reconstruction\n",
    "\n",
    "    # Define database path and camera mode\n",
    "    database = output_dir / \"database.db\"\n",
    "    camera_mode = pycolmap.CameraMode.AUTO\n",
    "    cameras = None\n",
    "    reconst_opts = {}\n",
    "    model = reconstruction.main(\n",
    "        database=database,\n",
    "        image_dir=imgs_dir,\n",
    "        feature_path=feature_path,\n",
    "        match_path=match_path,\n",
    "        pair_path=pair_path,\n",
    "        sfm_dir=output_dir,\n",
    "        camera_mode=camera_mode,\n",
    "        cameras=cameras,\n",
    "        skip_geometric_verification=True,\n",
    "        reconst_opts=reconst_opts,\n",
    "        verbose=config.general[\"verbose\"],\n",
    "    )\n",
    "\n",
    "    timer.update(\"pycolmap reconstruction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print COLMAP camera values\n",
    "print(list(model.cameras.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the solution in Metashape\n",
    "\n",
    "If the reconstruction with pycolmap has been performed, you can import the solution in Metashape.\n",
    "This is done by first exporting the solution in Bundler format and then importing it in Metashape.\n",
    "\n",
    "This can be performed automatically with the function `export_to_metashape()`, which can also run a Bundle Adjustment.\n",
    "\n",
    "**Note** that this function is under development and it is not yet integrated in Deep-Image-Matching (but it is inside a script in the scripts directory). However, you can use it as an example to export the solution to Metashape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the function from the script folder\n",
    "from scripts.metashape.metashape_from_dim import export_to_metashape\n",
    "\n",
    "\n",
    "# Define the paths for the ne Metashape project and the path of the Bundler filter\n",
    "project_dir = config.general[\"output_dir\"] / \"metashape\"\n",
    "project_name = config.general[\"output_dir\"].name + \".psx\"\n",
    "project_path = project_dir / project_name\n",
    "\n",
    "rec_dir = config.general[\"output_dir\"] / \"reconstruction\"\n",
    "bundler_file_path = rec_dir / \"bundler.out\"\n",
    "bundler_im_list = rec_dir / \"bundler_list.txt\"\n",
    "\n",
    "\n",
    "# Define the interior orientation parameters to refine or fix during the bundle adjustment (the parameters are the same as in the Metashape GUI)\n",
    "\n",
    "prm_to_optimize = {\n",
    "    \"f\": True,\n",
    "    \"cx\": True,\n",
    "    \"cy\": True,\n",
    "    \"k1\": True,\n",
    "    \"k2\": True,\n",
    "    \"k3\": True,\n",
    "    \"k4\": False,\n",
    "    \"p1\": True,\n",
    "    \"p2\": True,\n",
    "    \"b1\": False,\n",
    "    \"b2\": False,\n",
    "    \"tiepoint_covariance\": True,\n",
    "}\n",
    "\n",
    "# Export the reconstruction to Metashape\n",
    "export_to_metashape(\n",
    "    project_path=project_path,\n",
    "    images_dir=config.general[\"image_dir\"],\n",
    "    bundler_file_path=bundler_file_path.resolve(),\n",
    "    bundler_im_list=bundler_im_list.resolve(),\n",
    "    prm_to_optimize=prm_to_optimize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_image_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
