{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN SfM Pipeline with Deep-Image-Matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Let's first import DIM and load a logger to see what's going on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import yaml\n",
    "\n",
    "import deep_image_matching as dim\n",
    "\n",
    "logger = dim.setup_logger(\"dim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the configuration\n",
    "\n",
    "Get the list of possible pipelines and matching strategy and chose one of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available pipelines:\n",
      "['superpoint+lightglue',\n",
      " 'superpoint+lightglue_fast',\n",
      " 'superpoint+superglue',\n",
      " 'superpoint+kornia_matcher',\n",
      " 'disk+lightglue',\n",
      " 'aliked+lightglue',\n",
      " 'orb+kornia_matcher',\n",
      " 'sift+kornia_matcher',\n",
      " 'loftr',\n",
      " 'se2loftr',\n",
      " 'roma',\n",
      " 'keynetaffnethardnet+kornia_matcher',\n",
      " 'dedode+kornia_matcher']\n",
      "Available matching strategy:\n",
      "['bruteforce',\n",
      " 'sequential',\n",
      " 'retrieval',\n",
      " 'custom_pairs',\n",
      " 'matching_lowres',\n",
      " 'covisibility']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available pipelines:\")\n",
    "pprint(dim.Config.get_pipelines())\n",
    "print(\"Available matching strategy:\")\n",
    "pprint(dim.Config.get_matching_strategies())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to build a dictionary with the input processing parameters (they are the same as the input parameters for the CLI) and pass it to the Config class to initialize the configuration object. Refer to the [documentation](https://3dom-fbk.github.io/deep-image-matching/) for more information about the parameters.\n",
    "\n",
    "Note that the `dir` defines the project directory, where the images are stored and the results will be saved.\n",
    "Deep-Image-Matching will search for the images inside an 'image' subdirectory and will save the results in a 'results\\_{processing_params}' subdirectory, where {processing_params} are some information on the processing parameters used.\n",
    "\n",
    "By default DIM will not run if the output directory already exists, to avoid overwriting previous results. If you want to overwrite the results, you can set the `force` parameter to True. We have not implemented the possibility to recover the previous results yet (e.g., by using existing extracted features), but we may add it in the future.\n",
    "\n",
    "The `config_file` parameter is the path to the configuration file (optional). In this file you can specify all the parameters that you need for controlling the feature extraction and matching. Refer to the [documentation](https://3dom-fbk.github.io/deep-image-matching/advanced_configuration/) for more information about how to write this file. Note that this file il optional, if you don't pass it, the default parameters will be used.\n",
    "\n",
    "If you use set `verbose` to True, DIM will log all the processing steps and it will save some figures with the extracted features and the matches in a `debug` folder inside the results directory. Note that this will slow down the processing and will create a lot of files if the dataset is big. It is reccomended to use it only for testing or debugging purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2025-07-04 12:25:03 | [WARNING ] ../assets/example_cyprus/results_superpoint+lightglue_matching_lowres_quality_high already exists, but the '--force' option is used. Deleting the folder.\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Configuration file /home/francesco/dev/deep-image-matching/notebooks/.../assets/example_cyprus/config_superpoint+lightglue.yaml not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m params = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdir\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m../assets/example_cyprus\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpipeline\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msuperpoint+lightglue\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     13\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m config = \u001b[43mdim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Save the configuration to a json file for later use\u001b[39;00m\n\u001b[32m     17\u001b[39m config.save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/deep-image-matching/src/deep_image_matching/config.py:344\u001b[39m, in \u001b[36mConfig.__init__\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    342\u001b[39m config_file = Path(args[\u001b[33m\"\u001b[39m\u001b[33mconfig_file\u001b[39m\u001b[33m\"\u001b[39m]).resolve()\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_file.exists():\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConfiguration file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    345\u001b[39m \u001b[38;5;28mself\u001b[39m.update_from_yaml(config_file)\n\u001b[32m    346\u001b[39m \u001b[38;5;28mself\u001b[39m.print()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Configuration file /home/francesco/dev/deep-image-matching/notebooks/.../assets/example_cyprus/config_superpoint+lightglue.yaml not found."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"dir\": \"../assets/example_cyprus\",\n",
    "    \"pipeline\": \"superpoint+lightglue\",\n",
    "    \"config_file\": \".../assets/example_cyprus/config_superpoint+lightglue.yaml\",\n",
    "    \"strategy\": \"matching_lowres\",\n",
    "    \"quality\": \"high\",\n",
    "    \"tiling\": \"preselection\",\n",
    "    \"skip_reconstruction\": False,\n",
    "    \"force\": True,\n",
    "    \"camera_options\": \"../config/cameras.yaml\",\n",
    "    \"openmvg\": None,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "config = dim.Config(params)\n",
    "\n",
    "# Save the configuration to a json file for later use\n",
    "config.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the configuration object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Config general:\")\n",
    "pprint(config.general)\n",
    "print(\"Config extractor:\")\n",
    "pprint(config.extractor)\n",
    "print(\"Config matcher:\")\n",
    "pprint(config.matcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the extraction and matching\n",
    "\n",
    "First, you have to create an instance of the ImageMatching class and pass the configuration object to it.\n",
    "\n",
    "Then you can run the extraction and matching by calling the `run` method.\n",
    "This method will automatically run all the steps needed to extract the features and match the images. It will return the path to the h5 files containing the features and the matches.\n",
    "The `features.h5` file contains the features extracted from each images, while the `matches.h5` file contains the indices of the features matched.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ImageMatcher class\n",
    "matcher = dim.ImageMatcher(config)\n",
    "\n",
    "# Run image matching\n",
    "feature_path, match_path = matcher.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `features.h5` file\n",
    "\n",
    "#### The `matches.h5` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print features_h5 content\n",
    "# with h5py.File(features_h5, \"r\") as f:\n",
    "#     print(f.keys())\n",
    "#     print(f[images[0].name].keys())\n",
    "#     print(f[images[0].name][\"keypoints\"][:])\n",
    "#     print(f[images[1].name].keys())\n",
    "#     print(f[images[1].name][\"keypoints\"][:])\n",
    "\n",
    "# # Print matches.h5 content\n",
    "# with h5py.File(matches_h5, \"r\") as f:\n",
    "#     print(f.keys())\n",
    "#     g0 = f[images[0].name]\n",
    "#     print(g0.keys())\n",
    "#     g1 = g0[images[1].name]\n",
    "#     print(g1.__array__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export in colmap format\n",
    "\n",
    "DIM assigns camera models to images based on the options defined in `cameras.yaml` file. You can read this file with the `yaml` library which returns a dictionary.\n",
    "\n",
    "Then you can use the `export_to_colmap` function that will read the features and the matches from the h5 files and will save them in a COLMAP sqliite database. If you pass the `cameras` dictionary, it will also save the camera models in the database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read camera options\n",
    "with open(config.general[\"camera_options\"]) as file:\n",
    "    camera_options = yaml.safe_load(file)\n",
    "\n",
    "database_path = config.general[\"output_dir\"] / \"database.db\"\n",
    "dim.io.export_to_colmap(\n",
    "    img_dir=config.general[\"image_dir\"],\n",
    "    feature_path=feature_path,\n",
    "    match_path=match_path,\n",
    "    database_path=database_path,\n",
    "    camera_options=camera_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can assign camera models with a dictionary.\n",
    "\n",
    "For images not assigned to specific `cam<x>` camera groups, the options specified under `general` are applied. The `camera_model` can be selected from `[\"simple-pinhole\", \"pinhole\", \"simple-radial\", \"opencv\"]`. It's worth noting that it's easily possible to extend this to include all the classical COLMAP camera models. Cameras can either be shared among all images (`single_camera == True`), or each camera can have a different camera model (`single_camera == False`).\n",
    "\n",
    "A subset of images can share intrinsics using `cam<x>` key, by specifying the `camera_model` along with the names of the images separated by commas. There's no limit to the number of `cam<x>` entries you can use.\n",
    "\n",
    "**Note**: Use the SIMPLE-PINHOLE camera model if you want to export the solution to Metashape later, as there are some bugs in COLMAP (or pycolamp) when exportingthe solution in the Bundler format.\n",
    "e.g., using FULL-OPENCV camera model, the principal point is not exported correctly and the tie points are wrong in Metashape.\n",
    "\n",
    "```python\n",
    "camera_options = {\n",
    "    \"general\": {\n",
    "        \"camera_model\": \"pinhole\",  # [\"simple-pinhole\", \"pinhole\", \"simple-radial\", \"opencv\"]\n",
    "        \"single_camera\": True,\n",
    "    },\n",
    "    \"cam0\": {\n",
    "        \"camera_model\": \"pinhole\",\n",
    "        \"images\": \"DSC_6468.JPG,DSC_6468.JPG\",\n",
    "    },\n",
    "    \"cam1\": {\n",
    "        \"camera_model\": \"pinhole\",\n",
    "        \"images\": \"\",\n",
    "    },\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run reconstruction\n",
    "\n",
    "You can run the reconstruction with pycolmap, OpenMVG or MICMAC. The suggested method is pycolmap, as it is the most integrated with DIM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the pycolmap module is imported, you can define all the parameters for the COLAMP reconstruction.\n",
    "You can check all the available parameters with:\n",
    "\n",
    "```python\n",
    "import pycolmap\n",
    "\n",
    "print(pycolmap.IncrementalPipelineOptions().summary())\n",
    "```\n",
    "\n",
    "To define the reconstruction options, you can create an instance of the `IncrementalPipelineOptions` class and set the parameters you want to change. The default values are already set in the class, so you only need to set the parameters you want to change.\n",
    "\n",
    "```python\n",
    "opts = pycolmap.IncrementalPipelineOptions()\n",
    "opts.triangulation.ignore_two_view_tracks = False\n",
    "opts.mapper.filter_min_tri_angle = 0.5\n",
    "opts.mapper.filter_max_reproj_error = 5.0\n",
    "```\n",
    "\n",
    "Alternatively, you can create a dictionary with the options you want to change. The keys of the dictionary should be the names of the parameters and the values should be the values you want to set. You can then pass this dictionary to the `incremental_reconstruction` function.\n",
    "\n",
    "```python\n",
    "reconst_opts = {\n",
    "    \"triangulation\": {\n",
    "        \"ignore_two_view_tracks\": False,\n",
    "    },\n",
    "    \"mapper\": {\n",
    "        \"filter_min_tri_angle\": 0.5,\n",
    "        \"filter_max_reproj_error\": 5.0,\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "The function `dim.reconstruction.incremental_reconstruction` exposes some of the parameters of the `pycolmap.IncrementalPipelineOptions` class, so you can pass them directly to the function. For example, you can set the `refine_intrinsics` parameter to `True` to refine the intrinsics during the reconstruction.\n",
    "\n",
    "```python\n",
    "reconstruction = dim.reconstruction.incremental_reconstruction(\n",
    "    database_path=config.general[\"output_dir\"] / \"database.db\",\n",
    "    sfm_dir=config.general[\"output_dir\"],\n",
    "    image_dir=config.general[\"image_dir\"],\n",
    "    refine_intrinsics=True,\n",
    "    ignore_two_view_tracks=True,\n",
    "    reconstruction_options=opts,\n",
    ")\n",
    "```\n",
    "\n",
    "If you want to use the default options, you can just pass `None` or an empty dictionary to the `incremental_reconstruction` function.\n",
    "\n",
    "```python\n",
    "reconstruction = dim.reconstruction.incremental_reconstruction(\n",
    "    database_path=config.general[\"output_dir\"] / \"database.db\",\n",
    "    image_dir=config.general[\"image_dir\"],\n",
    "    sfm_dir=config.general[\"output_dir\"],\n",
    "    reconstruction_options=None,\n",
    ")\n",
    "```\n",
    "\n",
    "The `incremental_reconstruction` function will return a `pycolmap.Reconstruction` object that contains the reconstruction results. You can use this object to access the cameras, images, and points of the reconstruction.\n",
    "\n",
    "```python\n",
    "print(reconstruction.summary())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IncrementalPipelineOptions:\n",
      "    min_num_matches = 15\n",
      "    ignore_watermarks = False\n",
      "    multiple_models = True\n",
      "    max_num_models = 50\n",
      "    max_model_overlap = 20\n",
      "    min_model_size = 10\n",
      "    init_image_id1 = -1\n",
      "    init_image_id2 = -1\n",
      "    init_num_trials = 200\n",
      "    extract_colors = True\n",
      "    num_threads = -1\n",
      "    min_focal_length_ratio = 0.1\n",
      "    max_focal_length_ratio = 10.0\n",
      "    max_extra_param = 1.0\n",
      "    ba_refine_focal_length = True\n",
      "    ba_refine_principal_point = False\n",
      "    ba_refine_extra_params = True\n",
      "    ba_refine_sensor_from_rig = True\n",
      "    ba_min_num_residuals_for_cpu_multi_threading = 50000\n",
      "    ba_local_num_images = 6\n",
      "    ba_local_function_tolerance = 0.0\n",
      "    ba_local_max_num_iterations = 25\n",
      "    ba_global_frames_ratio = 1.1\n",
      "    ba_global_points_ratio = 1.1\n",
      "    ba_global_frames_freq = 500\n",
      "    ba_global_points_freq = 250000\n",
      "    ba_global_function_tolerance = 0.0\n",
      "    ba_global_max_num_iterations = 50\n",
      "    ba_local_max_refinements = 2\n",
      "    ba_local_max_refinement_change = 0.001\n",
      "    ba_global_max_refinements = 5\n",
      "    ba_global_max_refinement_change = 0.0005\n",
      "    ba_use_gpu = False\n",
      "    ba_gpu_index = -1\n",
      "    use_prior_position = False\n",
      "    use_robust_loss_on_prior_position = False\n",
      "    prior_position_loss_scale = 7.815\n",
      "    snapshot_path = \n",
      "    snapshot_frames_freq = 0\n",
      "    image_names = []\n",
      "    fix_existing_frames = False\n",
      "    mapper: IncrementalMapperOptions:\n",
      "        init_min_num_inliers = 100\n",
      "        init_max_error = 4.0\n",
      "        init_max_forward_motion = 0.95\n",
      "        init_min_tri_angle = 16.0\n",
      "        init_max_reg_trials = 2\n",
      "        abs_pose_max_error = 12.0\n",
      "        abs_pose_min_num_inliers = 30\n",
      "        abs_pose_min_inlier_ratio = 0.25\n",
      "        abs_pose_refine_focal_length = True\n",
      "        abs_pose_refine_extra_params = True\n",
      "        local_ba_num_images = 6\n",
      "        local_ba_min_tri_angle = 6.0\n",
      "        min_focal_length_ratio = 0.1\n",
      "        max_focal_length_ratio = 10.0\n",
      "        max_extra_param = 1.0\n",
      "        filter_max_reproj_error = 4.0\n",
      "        filter_min_tri_angle = 1.5\n",
      "        max_reg_trials = 3\n",
      "        fix_existing_frames = False\n",
      "        num_threads = -1\n",
      "        image_selection_method = ImageSelectionMethod.MIN_UNCERTAINTY\n",
      "    triangulation: IncrementalTriangulatorOptions:\n",
      "        max_transitivity = 1\n",
      "        create_max_angle_error = 2.0\n",
      "        continue_max_angle_error = 2.0\n",
      "        merge_max_reproj_error = 4.0\n",
      "        complete_max_reproj_error = 4.0\n",
      "        complete_max_transitivity = 5\n",
      "        re_max_angle_error = 5.0\n",
      "        re_min_ratio = 0.2\n",
      "        re_max_trials = 1\n",
      "        min_angle = 1.5\n",
      "        ignore_two_view_tracks = True\n",
      "        min_focal_length_ratio = 0.1\n",
      "        max_focal_length_ratio = 10.0\n",
      "        max_extra_param = 1.0\n"
     ]
    }
   ],
   "source": [
    "import pycolmap\n",
    "\n",
    "print(pycolmap.IncrementalPipelineOptions().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pycolmap.IncrementalPipelineOptions()\n",
    "opts.triangulation.ignore_two_view_tracks = False\n",
    "opts.triangulation.min_angle = 0.5\n",
    "opts.mapper.filter_min_tri_angle = 0.5\n",
    "opts.mapper.filter_max_reproj_error = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run reconstruction\u001b[39;00m\n\u001b[32m      2\u001b[39m refine_intrinsics = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mdim\u001b[49m.reconstruction.incremental_reconstruction(\n\u001b[32m      4\u001b[39m     database_path=config.general[\u001b[33m\"\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m\"\u001b[39m] / \u001b[33m\"\u001b[39m\u001b[33mdatabase.db\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     sfm_dir=config.general[\u001b[33m\"\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     image_dir=config.general[\u001b[33m\"\u001b[39m\u001b[33mimage_dir\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m     refine_intrinsics=refine_intrinsics,\n\u001b[32m      8\u001b[39m     reconstruction_options=opts,\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Run reconstruction\n",
    "refine_intrinsics = False\n",
    "model = dim.reconstruction.incremental_reconstruction(\n",
    "    database_path=config.general[\"output_dir\"] / \"database.db\",\n",
    "    sfm_dir=config.general[\"output_dir\"],\n",
    "    image_dir=config.general[\"image_dir\"],\n",
    "    refine_intrinsics=refine_intrinsics,\n",
    "    reconstruction_options=opts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print COLMAP camera values\n",
    "print(list(model.cameras.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
