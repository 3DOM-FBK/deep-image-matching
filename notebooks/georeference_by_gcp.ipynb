{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Deep Image Matching loaded in 2.726 seconds.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import pycolmap\n",
    "from deep_image_matching.thirdparty.transformations import (\n",
    "    affine_matrix_from_points,\n",
    "    decompose_matrix,\n",
    ")\n",
    "from deep_image_matching.triangulation import db_from_existing_poses\n",
    "from deep_image_matching.utils import COLMAPDatabase, OutputCapture\n",
    "\n",
    "root_path = Path(\"datasets/belv_20230725\")\n",
    "image_dir = root_path / \"images\"\n",
    "\n",
    "sfm_dir = root_path / \"results_superpoint+lightglue_bruteforce_quality_highest\"\n",
    "sfm_rec_path = sfm_dir / \"reconstruction\"\n",
    "\n",
    "# Output path for the triangulated markers\n",
    "output_path = root_path / \"marker_triang\"\n",
    "db_path = output_path / \"database_markers.db\"\n",
    "\n",
    "# Image coordinates of the markers\n",
    "markers_file = root_path / \"markers_image_20230725.csv\"\n",
    "\n",
    "# World coordinates of the markers\n",
    "georef_points = root_path / \"markers_utm.csv\"\n",
    "\n",
    "output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Get image list\n",
    "images = sorted(image_dir.glob(\"*\"))\n",
    "\n",
    "# Define a subset of the markers to use (leve none to use all)\n",
    "# markers_to_use = [\"D38\", \"T2\", \"F2\", \"F4\", \"F10\", \"F20\"]\n",
    "markers_to_use = [\"D38\", \"F2\", \"F4\", \"F10\", \"F20\"]\n",
    "\n",
    "\n",
    "# Dense reconstruction path to georeference\n",
    "dense_rec_path = root_path / \"results_roma_bruteforce_quality_high/dense_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_20230725_115953_IMG_1147.JPG :\n",
      " [[4832.3403 1582.9143]\n",
      " [2027.8405 3478.0388]\n",
      " [ 725.7628 3845.6572]\n",
      " [4092.3181 2256.6533]\n",
      " [3416.7617 3300.4646]]\n",
      "p2_20230725_120026_IMG_0885.JPG :\n",
      " [[3194.6826 1729.3799]\n",
      " [3573.5344 3204.1846]\n",
      " [4105.1738 3556.3171]\n",
      " [4139.4536 1980.674 ]\n",
      " [5928.5713 2516.8994]]\n",
      "matches idx:\n",
      " [[0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "# Read marker image coordinates and create keypoints dictionary with the form:\n",
    "# {\"image_name\": keypoints_array}\n",
    "# {\n",
    "#     \"image1.jpg\": np.array([[x1, y1], [x2, y2], ...]),\n",
    "#     \"image2.jpg\": np.array([[x1, y1], [x2, y2], ...]),\n",
    "#     ...\n",
    "# }\n",
    "markers_image = pd.read_csv(markers_file, header=None, names=[\"image\", \"marker\", \"x\", \"y\"])\n",
    "markers_image.sort_values([\"image\", \"marker\"], inplace=True, ascending=True)\n",
    "if markers_to_use:\n",
    "    markers_image = markers_image[markers_image[\"marker\"].isin(markers_to_use)]\n",
    "\n",
    "kpts = {}\n",
    "for image, gr in markers_image.groupby(\"image\"):\n",
    "    image = image + \".JPG\"\n",
    "    kpts[image] = gr[[\"x\", \"y\"]].values\n",
    "for k, v in kpts.items():\n",
    "    print(k, \":\\n\", v)\n",
    "\n",
    "# Manually create 1-to-1 matches array\n",
    "ids = np.arange(0, len(kpts[images[0].name]))\n",
    "matches_idx = np.array([ids, ids]).astype(np.int64).T\n",
    "print(\"matches idx:\\n\", matches_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot image with markers\n",
    "# import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# image_id = 1\n",
    "\n",
    "# img = cv2.cvtColor(cv2.imread(str(images[image_id])), cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# plt.scatter(\n",
    "#     kpts[images[image_id].name][:, 0],\n",
    "#     kpts[images[image_id].name][:, 1],\n",
    "#     c=\"r\",\n",
    "#     s=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features to h5 file\n",
    "features_h5 = output_path / \"features.h5\"\n",
    "with h5py.File(features_h5, \"w\") as f:\n",
    "    for image in images:\n",
    "        image_name = image.name\n",
    "        kp = kpts[image_name]\n",
    "        f.create_group(image_name)\n",
    "        f[image_name].create_dataset(\"keypoints\", data=kp, dtype=np.float32)\n",
    "\n",
    "# Save matches to h5 file\n",
    "matches_h5 = output_path / \"matches.h5\"\n",
    "with h5py.File(matches_h5, \"w\") as f:\n",
    "    image0, image1 = images[0].name, images[1].name\n",
    "    gr0 = f.create_group(image0)\n",
    "    gr0.create_dataset(image1, data=matches_idx, dtype=np.int64)\n",
    "\n",
    "pair_file = sfm_dir / \"pairs.txt\"\n",
    "\n",
    "# # print features_h5 content\n",
    "# with h5py.File(features_h5, \"r\") as f:\n",
    "#     print(f.keys())\n",
    "#     print(f[images[0].name].keys())\n",
    "#     print(f[images[0].name][\"keypoints\"][:])\n",
    "#     print(f[images[1].name].keys())\n",
    "#     print(f[images[1].name][\"keypoints\"][:])\n",
    "\n",
    "# # Print matches.h5 content\n",
    "# with h5py.File(matches_h5, \"r\") as f:\n",
    "#     print(f.keys())\n",
    "#     g0 = f[images[0].name]\n",
    "#     print(g0.keys())\n",
    "#     g1 = g0[images[1].name]\n",
    "#     print(g1.__array__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m2024-04-12 12:06:35 | [WARNING ] The database already exists, deleting it.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing keypoints: 100%|██████████| 2/2 [00:00<00:00, 1053.71it/s]\n",
      "Importing matches: 100%|██████████| 1/1 [00:00<00:00, 1454.34it/s]\n"
     ]
    }
   ],
   "source": [
    "sfm_rec = pycolmap.Reconstruction(sfm_rec_path)\n",
    "\n",
    "# Create a new database with the dense features and the known camera poses\n",
    "\n",
    "db_from_existing_poses(\n",
    "    db_path,\n",
    "    features_h5,\n",
    "    matches_h5,\n",
    "    sfm_rec_path,\n",
    "    pair_file,\n",
    "    do_geometric_verification=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the options for the triangulation according to the IncrementalPipelineOptions available in pycolmap\n",
    "# print(pycolmap.IncrementalPipelineOptions().summary())\n",
    "opt = dict(\n",
    "    min_num_matches=3,\n",
    "    triangulation=dict(\n",
    "        ignore_two_view_tracks=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time\n",
      "   0  2.837421e+00    0.00e+00    1.32e+03   0.00e+00   0.00e+00  1.00e+04        0    3.00e-05    9.20e-05\n",
      "   1  2.471128e+00    3.66e-01    1.42e-01   5.44e-04   1.00e+00  3.00e+04        0    4.39e-05    4.82e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240412 12:06:35.960026 3086923 misc.cc:198] \n",
      "==============================================================================\n",
      "Loading database\n",
      "==============================================================================\n",
      "I20240412 12:06:35.961102 3086923 database_cache.cc:54] Loading cameras...\n",
      "I20240412 12:06:35.961148 3086923 database_cache.cc:64]  2 in 0.000s\n",
      "I20240412 12:06:35.961160 3086923 database_cache.cc:72] Loading matches...\n",
      "I20240412 12:06:35.961179 3086923 database_cache.cc:78]  1 in 0.000s\n",
      "I20240412 12:06:35.961184 3086923 database_cache.cc:94] Loading images...\n",
      "I20240412 12:06:35.961223 3086923 database_cache.cc:143]  2 in 0.000s (connected 2)\n",
      "I20240412 12:06:35.961228 3086923 database_cache.cc:154] Building correspondence graph...\n",
      "I20240412 12:06:35.961241 3086923 database_cache.cc:190]  in 0.000s (ignored 0)\n",
      "I20240412 12:06:35.961364 3086923 timer.cc:91] Elapsed time: 0.000 [minutes]\n",
      "I20240412 12:06:35.961529 3086923 misc.cc:198] \n",
      "==============================================================================\n",
      "Triangulating image #1 (0)\n",
      "==============================================================================\n",
      "I20240412 12:06:35.961535 3086923 sfm.cc:473] => Image sees 0 / 5 points\n",
      "I20240412 12:06:35.961606 3086923 sfm.cc:478] => Triangulated 5 points\n",
      "I20240412 12:06:35.961611 3086923 misc.cc:198] \n",
      "==============================================================================\n",
      "Triangulating image #2 (1)\n",
      "==============================================================================\n",
      "I20240412 12:06:35.961614 3086923 sfm.cc:473] => Image sees 5 / 5 points\n",
      "I20240412 12:06:35.961618 3086923 sfm.cc:478] => Triangulated 0 points\n",
      "I20240412 12:06:35.961622 3086923 misc.cc:198] \n",
      "==============================================================================\n",
      "Retriangulation\n",
      "==============================================================================\n",
      "I20240412 12:06:35.961628 3086923 incremental_mapper.cc:175] => Completed observations: 0\n",
      "I20240412 12:06:35.961632 3086923 incremental_mapper.cc:178] => Merged observations: 0\n",
      "I20240412 12:06:35.961642 3086923 misc.cc:198] \n",
      "==============================================================================\n",
      "Bundle adjustment\n",
      "==============================================================================\n",
      "I20240412 12:06:35.962460 3086923 misc.cc:205] \n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "I20240412 12:06:35.962476 3086923 bundle_adjustment.cc:942] \n",
      "    Residuals : 20\n",
      "   Parameters : 15\n",
      "   Iterations : 2\n",
      "         Time : 0.000760794 [s]\n",
      " Initial cost : 0.376658 [px]\n",
      "   Final cost : 0.351506 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "I20240412 12:06:35.962482 3086923 incremental_mapper.cc:175] => Completed observations: 0\n",
      "I20240412 12:06:35.962486 3086923 incremental_mapper.cc:178] => Merged observations: 0\n",
      "I20240412 12:06:35.962497 3086923 incremental_mapper.cc:160] => Filtered observations: 0\n",
      "I20240412 12:06:35.962500 3086923 sfm.cc:521] => Changed observations: 0.000000\n",
      "I20240412 12:06:35.962515 3086923 misc.cc:198] \n",
      "==============================================================================\n",
      "Extracting colors\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the triangulation with the known camera poses\n",
    "verbose = True\n",
    "with OutputCapture(verbose):\n",
    "    with pycolmap.ostream():\n",
    "        reconstruction = pycolmap.triangulate_points(\n",
    "            sfm_rec,\n",
    "            db_path,\n",
    "            image_dir,\n",
    "            output_path,\n",
    "            options=opt,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 Point3D(xyz=[6.80372, -1.44258, 14.1866], color=[143, 139, 86], error=0.0227758, track=Track(length=2))\n",
      "1491 Point3D(xyz=[1.99842, 1.31624, 8.79684], color=[163, 107, 101], error=0.358146, track=Track(length=2))\n",
      "1492 Point3D(xyz=[0.691425, 1.45129, 6.99773], color=[244, 228, 229], error=1.49442, track=Track(length=2))\n",
      "1493 Point3D(xyz=[4.91828, -0.280677, 10.1311], color=[234, 242, 242], error=0.00433232, track=Track(length=2))\n",
      "1494 Point3D(xyz=[3.78636, 0.790003, 6.84661], color=[254, 243, 251], error=0.143108, track=Track(length=2))\n"
     ]
    }
   ],
   "source": [
    "pts = reconstruction.points3D\n",
    "for i, pt in sorted(pts.items()):\n",
    "    print(i, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Point2D(xy=[4832.84, 1583.41], point3D_id=1490),\n",
       " Point2D(xy=[2028.34, 3478.54], point3D_id=1491),\n",
       " Point2D(xy=[726.263, 3846.16], point3D_id=1492),\n",
       " Point2D(xy=[4092.82, 2257.15], point3D_id=1493),\n",
       " Point2D(xy=[3417.26, 3300.96], point3D_id=1494)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = reconstruction.images[1]\n",
    "img.points2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.80371791 -1.44258202 14.18655572]\n",
      " [ 1.99842367  1.31624029  8.79683948]\n",
      " [ 0.69142514  1.45128844  6.99772945]\n",
      " [ 4.91827547 -0.28067699 10.13106025]\n",
      " [ 3.78635656  0.79000304  6.8466085 ]]\n"
     ]
    }
   ],
   "source": [
    "image_id = 1\n",
    "local = []\n",
    "for pt in reconstruction.images[image_id].points2D:\n",
    "    if not isinstance(pt.point3D_id, int) or pt.point3D_id < 0:\n",
    "        print(f\"Point {pt.point2D_idx} is not triangulated\")\n",
    "        continue\n",
    "    local.append(reconstruction.points3D[pt.point3D_id].xyz)\n",
    "local = np.array(local)\n",
    "print(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   X             Y            Z\n",
      "Label                                          \n",
      "D38    416273.191792  5.091048e+06  1912.062781\n",
      "F10    416458.548600  5.091086e+06  1841.996800\n",
      "F2     416514.111700  5.091104e+06  1839.217200\n",
      "F20    416376.149300  5.091104e+06  1883.523600\n",
      "F4     416451.502700  5.091155e+06  1857.065600\n"
     ]
    }
   ],
   "source": [
    "# Read the georeferenced points\n",
    "georef = pd.read_csv(georef_points)\n",
    "georef.index = georef[\"Label\"]\n",
    "georef.drop(columns=[\"Label\"], inplace=True)\n",
    "georef.sort_values(\"Label\", inplace=True)\n",
    "if markers_to_use:\n",
    "    georef = georef[georef.index.isin(markers_to_use)]\n",
    "print(georef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: [4.16637855e+05 5.09123835e+06 1.88055817e+03] m\n",
      "Angles: [-91.10481171  -0.31795999 143.15041448] deg\n",
      "Scale: 25.1244%\n"
     ]
    }
   ],
   "source": [
    "# Estimate a Helmert transformation between the mean pcd and the ref.\n",
    "T = affine_matrix_from_points(\n",
    "    local.T, georef.to_numpy().T, shear=False, scale=True, usesvd=True\n",
    ")\n",
    "scale, _, angles, translation, _ = decompose_matrix(T)\n",
    "scale_percent = scale.mean() - 1\n",
    "angles_deg = np.rad2deg(angles)\n",
    "\n",
    "print(f\"Translation: {translation} m\")\n",
    "print(f\"Angles: {angles_deg} deg\")\n",
    "print(f\"Scale: {scale_percent:.6}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dense point cloud from roma to a ply file\n",
    "dense_rec = pycolmap.Reconstruction(dense_rec_path)\n",
    "dense_rec.export_PLY(dense_rec_path / \"dense.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and transform the point cloud\n",
    "pcd = o3d.io.read_point_cloud(str(dense_rec_path / \"dense_merged_clean.ply\"))\n",
    "georef_pcd = pcd.transform(T)\n",
    "o3d.io.write_point_cloud(str(dense_rec_path / \"dense_georef.ply\"), georef_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('datasets/belv_20230725/results_roma_bruteforce_quality_high/dense_model')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_rec_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-image-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
