{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a custom configuration file: /home/francesco/phd/deep-image-matching/datasets/belv_20230725/superpoint+lightglue.yaml\n",
      "\u001b[1;33m2024-04-09 18:33:58 | [WARNING ] Extractor name in configuration file /home/francesco/phd/deep-image-matching/datasets/belv_20230725/superpoint+lightglue.yaml does not match with the extractor chosen from CLI or GUI. The custom configuration is not set, but matching is run with the default options.\u001b[0m\n",
      "\u001b[1;33m2024-04-09 18:33:58 | [WARNING ] Matcher name in configuration file /home/francesco/phd/deep-image-matching/datasets/belv_20230725/superpoint+lightglue.yaml does not match with the matcher chosen from CLI or GUI. The custom configuration is not set, but matching is run with the default options.\u001b[0m\n",
      "Config general:\n",
      "{'camera_options': './datasets/belv_20230725/cameras.yaml',\n",
      " 'db_path': None,\n",
      " 'geom_verification': <GeometricVerification.PYDEGENSAC: 1>,\n",
      " 'graph': True,\n",
      " 'gv_confidence': 0.99999,\n",
      " 'gv_threshold': 4,\n",
      " 'image_dir': PosixPath('datasets/belv_20230725/images'),\n",
      " 'matching_strategy': 'bruteforce',\n",
      " 'min_inlier_ratio_per_pair': 0.2,\n",
      " 'min_inliers_per_pair': 2,\n",
      " 'min_matches_per_tile': 10,\n",
      " 'openmvg_conf': None,\n",
      " 'output_dir': PosixPath('datasets/belv_20230725/results_sift+kornia_matcher_bruteforce_quality_high'),\n",
      " 'overlap': None,\n",
      " 'pair_file': PosixPath('datasets/belv_20230725/results_sift+kornia_matcher_bruteforce_quality_high/pairs.txt'),\n",
      " 'quality': <Quality.HIGH: 3>,\n",
      " 'refine_intrinsics': False,\n",
      " 'retrieval': None,\n",
      " 'skip_reconstruction': False,\n",
      " 'tile_overlap': 100,\n",
      " 'tile_preselection_size': 1000,\n",
      " 'tile_selection': <TileSelection.NONE: 0>,\n",
      " 'tile_size': (3000, 2000),\n",
      " 'try_match_full_images': False,\n",
      " 'upright': False,\n",
      " 'verbose': True}\n",
      "\n",
      "\n",
      "Config extractor:\n",
      "{'fix_sampling': True,\n",
      " 'keypoint_threshold': 0.0001,\n",
      " 'max_keypoints': 10000,\n",
      " 'name': 'superpoint',\n",
      " 'nms_radius': 4,\n",
      " 'remove_borders': 4}\n",
      "\n",
      "\n",
      "Config matcher:\n",
      "{'depth_confidence': -1,\n",
      " 'filter_threshold': 0.6,\n",
      " 'flash': True,\n",
      " 'match_mode': 'smnn',\n",
      " 'mp': False,\n",
      " 'name': 'lightglue',\n",
      " 'th': 0.85,\n",
      " 'width_confidence': -1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import deep_image_matching as dim\n",
    "import yaml\n",
    "\n",
    "logger = dim.setup_logger(\"dim\")\n",
    "\n",
    "params = {\n",
    "    \"dir\": \"./datasets/belv_20230725\",\n",
    "    \"pipeline\": \"superpoint+lightglue\",\n",
    "    \"config_file\": \"./datasets/belv_20230725/superpoint+lightglue.yaml\",\n",
    "    \"strategy\": \"bruteforce\",\n",
    "    \"quality\": \"high\",\n",
    "    \"tiling\": \"none\",\n",
    "    \"skip_reconstruction\": False,\n",
    "    \"force\": True,\n",
    "    \"camera_options\": \"./datasets/belv_20230725/cameras.yaml\",\n",
    "    \"openmvg\": None,\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "# Build configuration\n",
    "config = dim.Config(params)\n",
    "config.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m2024-04-09 18:34:04 | [DEBUG   ] Matching options: Quality: HIGH - Tiling: NONE\u001b[0m\n",
      "\u001b[1;30m2024-04-09 18:34:04 | [DEBUG   ] Saving directory: datasets/belv_20230725/results_sift+kornia_matcher_bruteforce_quality_high\u001b[0m\n",
      "\u001b[1;30m2024-04-09 18:34:04 | [DEBUG   ] Running inference on device cuda\u001b[0m\n",
      "Loaded SuperPoint model\n",
      "\u001b[1;30m2024-04-09 18:34:05 | [DEBUG   ] Matching options: Tiling: NONE\u001b[0m\n",
      "\u001b[1;30m2024-04-09 18:34:05 | [DEBUG   ] Saving directory: datasets/belv_20230725/results_sift+kornia_matcher_bruteforce_quality_high\u001b[0m\n",
      "\u001b[1;30m2024-04-09 18:34:05 | [DEBUG   ] Running inference on device cuda\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ] Running image matching with the following configuration:\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Image folder: datasets/belv_20230725/images\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Output folder: datasets/belv_20230725/results_sift+kornia_matcher_bruteforce_quality_high\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Number of images: 2\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Matching strategy: bruteforce\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Image quality: HIGH\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Tile selection: NONE\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Feature extraction method: superpoint\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Matching method: lightglue\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   Geometric verification: PYDEGENSAC\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ]   CUDA available: True\u001b[0m\n",
      "\u001b[1;30m2024-04-09 18:34:06 | [DEBUG   ] Bruteforce matching, generating pairs ..\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ] Number of pairs: 1\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ] Found 1 pairs.\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ] Extracting features with superpoint...\u001b[0m\n",
      "\u001b[0;37m2024-04-09 18:34:06 | [INFO    ] superpoint configuration: \u001b[0m\n",
      "{'fix_sampling': True,\n",
      " 'keypoint_threshold': 0.0001,\n",
      " 'max_keypoints': 10000,\n",
      " 'name': 'superpoint',\n",
      " 'nms_radius': 4,\n",
      " 'remove_borders': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.72 GiB. GPU 0 has a total capacity of 11.75 GiB of which 809.00 MiB is free. Process 276581 has 141.49 MiB memory in use. Process 298292 has 2.66 GiB memory in use. Including non-PyTorch memory, this process has 7.20 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 17.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m matcher \u001b[38;5;241m=\u001b[39m dim\u001b[38;5;241m.\u001b[39mImageMatcher(config)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run image matching\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m feature_path, match_path \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Read camera options\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config\u001b[38;5;241m.\u001b[39mgeneral[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera_options\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/image_matching.py:194\u001b[0m, in \u001b[0;36mImageMatcher.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m     timer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotate_upright_images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m feature_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m timer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Matching\u001b[39;00m\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/image_matching.py:361\u001b[0m, in \u001b[0;36mImageMatcher.extract_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_list):\n\u001b[0;32m--> 361\u001b[0m     feature_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    364\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures extracted!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/extractors/extractor_base.py:186\u001b[0m, in \u001b[0;36mExtractorBase.extract\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    182\u001b[0m image_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_image(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quality, image, interp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterp)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtile_selection\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m TileSelection\u001b[38;5;241m.\u001b[39mNONE:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Extract features from the whole image\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# features[\"feature_path\"] = str(feature_path)\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# features[\"im_path\"] = str(im_path)\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtile_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/extractors/superpoint.py:121\u001b[0m, in \u001b[0;36mSuperPointExtractor._extract\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    118\u001b[0m image_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame2tensor(image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Remove elements from list/tuple\u001b[39;00m\n\u001b[1;32m    124\u001b[0m feats \u001b[38;5;241m=\u001b[39m {k: v[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feats\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/extractors/superpoint.py:51\u001b[0m, in \u001b[0;36mSuperPoint.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired_inputs:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m in data\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/extractors/superpoint.py:59\u001b[0m, in \u001b[0;36mSuperPoint._forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/phd/deep-image-matching/src/deep_image_matching/thirdparty/SuperGluePretrainedNetwork/models/superpoint.py:162\u001b[0m, in \u001b[0;36mSuperPoint.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Shared Encoder\u001b[39;00m\n\u001b[1;32m    161\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1a(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m--> 162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m    164\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2a(x))\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/deep-image-matching/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.72 GiB. GPU 0 has a total capacity of 11.75 GiB of which 809.00 MiB is free. Process 276581 has 141.49 MiB memory in use. Process 298292 has 2.66 GiB memory in use. Including non-PyTorch memory, this process has 7.20 GiB memory in use. Of the allocated memory 5.86 GiB is allocated by PyTorch, and 17.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Initialize ImageMatcher class\n",
    "matcher = dim.ImageMatcher(config)\n",
    "\n",
    "# Run image matching\n",
    "feature_path, match_path = matcher.run()\n",
    "\n",
    "# Read camera options\n",
    "with open(config.general[\"camera_options\"], \"r\") as file:\n",
    "    camera_options = yaml.safe_load(file)\n",
    "\n",
    "# Export in colmap format\n",
    "database_path = config.general[\"output_dir\"] / \"database.db\"\n",
    "dim.io.export_to_colmap(\n",
    "    img_dir=config.general[\"image_dir\"],\n",
    "    feature_path=feature_path,\n",
    "    match_path=match_path,\n",
    "    database_path=database_path,\n",
    "    camera_options=camera_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Export in colmap format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m database_path \u001b[38;5;241m=\u001b[39m \u001b[43moutput_dir\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m dim\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mexport_to_colmap(\n\u001b[1;32m      4\u001b[0m     img_dir\u001b[38;5;241m=\u001b[39mimgs_dir,\n\u001b[1;32m      5\u001b[0m     feature_path\u001b[38;5;241m=\u001b[39mfeature_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     camera_options\u001b[38;5;241m=\u001b[39mcamera_options,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Export in colmap format\n",
    "database_path = output_dir / \"database.db\"\n",
    "dim.io.export_to_colmap(\n",
    "    img_dir=imgs_dir,\n",
    "    feature_path=feature_path,\n",
    "    match_path=match_path,\n",
    "    database_path=database_path,\n",
    "    camera_options=camera_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set camera options\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cameras = {\n",
    "    1: {\n",
    "        \"model\": 4,  # 4 is OPENCV model\n",
    "        \"width\": 6000,\n",
    "        \"height\": 4000,\n",
    "        \"params\": [\n",
    "            9.26789262766209504e03,\n",
    "            9.26789262766209504e03,\n",
    "            3.05349107994520591e03,\n",
    "            1.94835654532114540e03,\n",
    "            -8.07042713029020586e-02,\n",
    "            9.46617629940955385e-02,\n",
    "            3.31782983128223608e-04,\n",
    "            -4.32106111976037410e-04,\n",
    "        ],\n",
    "    },\n",
    "    2: {\n",
    "        \"model\": 4,\n",
    "        \"width\": 6000,\n",
    "        \"height\": 4000,\n",
    "        \"params\": [\n",
    "            6.62174345720628298e03,\n",
    "            6.62174345720628298e03,\n",
    "            3.01324420057086490e03,\n",
    "            1.94347461466223308e03,\n",
    "            -9.41830394356213407e-02,\n",
    "            8.55303528514532035e-02,\n",
    "            1.68948638308769863e-04,\n",
    "            -8.74637609310216697e-04,\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "with dim.utils.COLMAPDatabase(database_path) as db:\n",
    "    for id, cam in cameras.items():\n",
    "        db.update_camera(\n",
    "            camera_id=id,\n",
    "            model=cam[\"model\"],\n",
    "            width=cam[\"width\"],\n",
    "            height=cam[\"height\"],\n",
    "            params=cam[\"params\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pycolmap\n",
    "\n",
    "# print(pycolmap.IncrementalPipelineOptions().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2024-04-09 15:15:21 | [INFO    ] Running 3D reconstruction...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240409 15:15:21.422063 167579 misc.cc:198] \n",
      "==============================================================================\n",
      "Loading database\n",
      "==============================================================================\n",
      "I20240409 15:15:21.422781 167579 database_cache.cc:54] Loading cameras...\n",
      "I20240409 15:15:21.422809 167579 database_cache.cc:64]  2 in 0.000s\n",
      "I20240409 15:15:21.422822 167579 database_cache.cc:72] Loading matches...\n",
      "I20240409 15:15:21.422835 167579 database_cache.cc:78]  1 in 0.000s\n",
      "I20240409 15:15:21.422838 167579 database_cache.cc:94] Loading images...\n",
      "I20240409 15:15:21.423250 167579 database_cache.cc:143]  2 in 0.000s (connected 2)\n",
      "I20240409 15:15:21.423261 167579 database_cache.cc:154] Building correspondence graph...\n",
      "I20240409 15:15:21.423429 167579 database_cache.cc:190]  in 0.000s (ignored 0)\n",
      "I20240409 15:15:21.423439 167579 timer.cc:91] Elapsed time: 0.000 [minutes]\n",
      "I20240409 15:15:21.423715 167579 misc.cc:198] \n",
      "==============================================================================\n",
      "Finding good initial image pair\n",
      "==============================================================================\n",
      "I20240409 15:15:21.490808 167579 misc.cc:198] \n",
      "==============================================================================\n",
      "Initializing with image pair #1 and #2\n",
      "==============================================================================\n",
      "I20240409 15:15:21.491742 167579 misc.cc:198] \n",
      "==============================================================================\n",
      "Global bundle adjustment\n",
      "==============================================================================\n",
      "I20240409 15:15:21.502663 167579 misc.cc:205] \n",
      "Bundle adjustment report\n",
      "------------------------\n",
      "I20240409 15:15:21.502694 167579 bundle_adjustment.cc:942] \n",
      "    Residuals : 1424\n",
      "   Parameters : 1073\n",
      "   Iterations : 11\n",
      "         Time : 0.0105071 [s]\n",
      " Initial cost : 1.28933 [px]\n",
      "   Final cost : 1.26975 [px]\n",
      "  Termination : Convergence\n",
      "\n",
      "I20240409 15:15:21.502931 167579 incremental_mapper.cc:160] => Filtered observations: 28\n",
      "I20240409 15:15:21.502938 167579 incremental_mapper.cc:167] => Filtered images: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;37m2024-04-09 15:15:21 | [INFO    ] Reconstructed 1 model(s).\u001b[0m\n",
      "\u001b[0;37m2024-04-09 15:15:21 | [INFO    ] Largest model is #0 with 2 images.\u001b[0m\n",
      "\u001b[0;37m2024-04-09 15:15:21 | [INFO    ] Exporting model...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240409 15:15:21.692776 167579 timer.cc:91] Elapsed time: 0.005 [minutes]\n"
     ]
    }
   ],
   "source": [
    "# Run reconstruction\n",
    "opt = dict(\n",
    "    triangulation=dict(\n",
    "        ignore_two_view_tracks=False,\n",
    "        min_angle=0.5,\n",
    "    ),\n",
    "    mapper=dict(filter_min_tri_angle=0.5, filter_max_reproj_error=5.0),\n",
    ")\n",
    "refine_intrinsics = False\n",
    "verbose = False\n",
    "\n",
    "model = dim.reconstruction.pycolmap_reconstruction(\n",
    "    database_path=output_dir / \"database.db\",\n",
    "    sfm_dir=output_dir,\n",
    "    image_dir=imgs_dir,\n",
    "    refine_intrinsics=refine_intrinsics,\n",
    "    options=opt,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-image-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
